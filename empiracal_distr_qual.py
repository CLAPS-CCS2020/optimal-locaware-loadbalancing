import os, sys
import argparse
import json

parser = argparse.ArgumentParser(
    description="look into Tor's logs to know which circuit has been used for "
    "tgen streams, and compute the empirical distribution of used relays to "
    "compare with the true expected distribution")

parser.add_argument(
    help="""The PATH to search for tor log files, which may be '-'
for STDIN; each log file may end in '.xz' to enable
inline xz decompression""",
    metavar="PATH",
    action="store", dest="searchpath")

parser.add_argument('-f', '--filter',
        help="""Specify comma delimited list of substrings that must be found
in the filename in order to be considered""",
        action="store", dest="filters_string",
        metavar="FILTER",
        default="webclient")

parser.add_argument('-e', '--expression',
    help="""Append a regex PATTERN to the list of strings used with
re.search to find tgen log file names in the search path""",
    action="append", dest="patterns",
    metavar="PATTERN",
    default=["tor.1000.log"])

parser.add_argument('-p', '--prefix',
    help="""A STRING directory path prefix where the processed data
files generated by this script will be written""",
    metavar="STRING",
    action="store", dest="prefix",
    default=os.getcwd())

def find_file_paths(searchpath, patterns, filters):
    paths = []
    if searchpath.endswith("/-"): paths.append("-")
    else:
        for root, dirs, files in os.walk(searchpath):
            for name in files:
                found = False
                fpath = os.path.join(root, name)
                fbase = os.path.basename(fpath)
                for pattern in patterns:
                    if re.search(pattern, fbase) and not any(s not in fbase for s in filters):
                        found = True
                if found: paths.append(fpath)
    return paths


def timing_is_in(timings, lower, upper):
    ctr = 0
    for timing in timings:
        if timing >= lower and timing <= upper:
            ctr += 1
    return ctr

if __name__ == "__main__":
    args =  parser.parse_args()
    args.searchpath = os.path.abspath(os.path.expanduser(args.searchpath))
    args.prefix = os.path.abspath(os.path.expanduser(args.prefix))
    # get  webclient std tor files
    torfilepaths = find_file_paths(args.searchpath, args.patterns, args.filters_string.split('|'))
    
    relaycount = {'guards':{}, 'middles':{}, 'exits':{}}

    for torfile in torfilepaths:
        with open(torfile, "r") as f:
            for line in f:
                if "CIRCUIT ATTACHED" in line:
                    tab = line.split()
                    ## Streams can be attached to 1-node circuits for, I guess,
                    #  directory requests
                    if len(tab) < 10:
                        continue
                    # Interested in timing and relayname
                    timing = int(tab[2].split(':')[1])*60 + int(tab[2].split(':')[2]) #timing in seconds
                    guard = tab[6].split("~")[1]
                    middle = tab[9].split("~")[1]
                    exit = tab[12].split("~")[1]
                    if not guard in relaycount['guards']:
                        relaycount['guards'][guard] = [timing]
                    else:
                        relaycount['guards'][guard].append(timing)

                    if not middle in relaycount['middles']:
                        relaycount['middles'][middle] = [timing]
                    else
                        relaycount['middles'][middle].append(timing)

                    if not exit in relaycount['exits']:
                        relaycount['exits'][exit] = [timing]
                    else:
                        relaycount['exits'][exit].append(timing)
    
    ## We counts observed relays within 10 minutes windows starting from 15
    #  minutes of the simulation
    # Can multiproc this if necessary
    i = 15
    windowcounters = {}
    while (upper < 60*60) {
        lower = i*60
        upper = (i+10)*60
        windowcounters[i-15] = {'guards':{}, 'middles':{}, 'exits':{}}
        
        for entry in relaycount['guards']:
            ctr = timing_is_in(relaycount['guards'][entry], lower, upper):
            windowcounters[i-15]['guards'][entry] = ctr
                
        for middle in relaycount['middles']:
            ctr = timing_is_in(relaycount['middles'][middle], lower, upper):
            windowcounters[i-15]['middles'][middle] = ctr
        for exit in relaycount['exits']:
            ctr = timing_is_in(relaycount['exits'][exit], lower, upper):
            windowcounters[i-15]['exits'][exit] = ctr
        
        i+=1
    }
    json.dump(windowcounters, args.prefix, "windowcounters.json") 
